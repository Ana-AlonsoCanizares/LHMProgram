{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ana-AlonsoCanizares/LHMProgram/blob/main/Day3_GANs_DoneInClass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#PyTorch Libraries\n",
        "import torch\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models,transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "8iaZQhv-oEYh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3h7zvIJRoEJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 16, 3, 2, 1)\n",
        "    self.bn1 = nn.BatchNorm2d(16)\n",
        "    self.conv2 = nn.Conv2d(16, 32, 3, 2, 1)\n",
        "    self.bn2 = nn.BatchNorm2d(32)\n",
        "    self.conv3 = nn.Conv2d(32, 64, 3, 2, 1)\n",
        "    self.bn3 = nn.BatchNorm2d(64)\n",
        "\n",
        "    self.linear1 = nn.Linear(64, 100)\n",
        "    self.bn4 = nn.BatchNorm2d(100)\n",
        "    self.linear1 = nn.Linear(100, 20)\n",
        "    self.bn5 = nn.BatchNorm2d(20)\n",
        "    self.linear1 = nn.Linear(20, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # (bs, 1, 28, 28)\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = F.leaky_relu(x)\n",
        "    # (bs, 16, 14, 14)\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x)\n",
        "    x = F.leaky_relu(x)\n",
        "    # (bs, 32, 7, 7)\n",
        "    x = self.conv3(x)\n",
        "    x = self.bn3(x)\n",
        "    x = F.leaky_relu(x)\n",
        "    # (bs, 64, 4, 4)\n",
        "    print(x.shape)\n",
        "\n",
        "    x = x.view(-1, 64*4*4)\n",
        "    x = self.linear1(x)\n",
        "    x = self.bn4(x)\n",
        "    x = F.leaky_relu(x)\n",
        "\n",
        "    x = self.linear2(x)\n",
        "    x = self.bn5(x)\n",
        "    x = F.leaky_relu(x)\n",
        "\n",
        "    x = self.linear3(x)\n",
        "    x = torch.sigmoid(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "NTUAoiZZmq8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, dz):\n",
        "    self.linear1 = nn.Linear(dz, 20)\n",
        "    self.bn1 = nn.BatchNorm1d(20)\n",
        "    self.linear2 = nn.Linear(20, 100)\n",
        "    self.bn2 = nn.BatchNorm1d(100)\n",
        "    self.linear3 = nn.Linear(100, 64*4*4)\n",
        "    self.bn3 = nn.BatchNorm1d(64*4*4)\n",
        "    self.dconv1 = nn.ConvTransposed2d(64, 32, 3, 2, 1)\n",
        "    self.bn4 = nn.BatchNorm1d(32)\n",
        "    self.dconv2 = nn.ConvTransposed2d(32, 16, 3, 2, 1, output_padding = 1)\n",
        "    self.bn5 = nn.BatchNorm1d(16)\n",
        "    self.dconv3 = nn.ConvTransposed2d(16, 1, 3, 2, 1, output_padding = 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = F.leaky_relu(x)\n",
        "\n",
        "    x = self.linear2(x)\n",
        "    x = self.bn2(x)\n",
        "    x = F.leaky_relu(x)\n",
        "\n",
        "    x = self.linear3(x)\n",
        "    x = self.bn3(x)\n",
        "    x = F.leaky_relu(x)\n",
        "\n",
        "    x = x.view(-1, 64, 4, 4)\n",
        "\n",
        "    x = self.dconv1(x)\n",
        "    x = self.bn4(x)\n",
        "    x = F.leaky_relu(x)\n",
        "\n",
        "    x = self.dconv2(x)\n",
        "    x = self.bn5(x)\n",
        "    x = F.leaky_relu(x)\n",
        "\n",
        "    x = self.dconv3(x)\n",
        "    x = F.tanh(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "bEs2IvfEpHSF",
        "outputId": "e386baf7-30df-4bd6-fe86-e0ee902b48f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-efc01aa509a5>\"\u001b[0;36m, line \u001b[0;32m41\u001b[0m\n\u001b[0;31m    return x\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "disc = Discriminator().to(device)\n",
        "gen = Generator(32).to(device)\n",
        "\n",
        "opt_d = optim.Adam(disc.parameters(), lr = 1e-4)\n",
        "opt_g = optim.Adam(gen.parameters(), lr = 1e-4)\n",
        "\n",
        "num_epochs = 3\n",
        "for i in range(num_epochs):\n",
        "  total_loss_gen = 0\n",
        "  total_loss_disc = 0\n",
        "  for batch in train_dataloader:\n",
        "    # pass real images throught discriminator\n",
        "    # pass fake images throught discriminator\n",
        "    # create fake images throught discriminator and pass them throught the discriminator\n",
        "\n",
        "    X = batch[0].to(device)\n",
        "    labels = torch.ones(X.shape[0])\n",
        "    out = disc(X)\n",
        "    loss = F.bse_loss(out, labels)\n",
        "    opt_d.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    noise = torch.randn((64, 32), device = device, dtype = torch.float)\n",
        "    X_fake = gen(noise)\n",
        "    out_fake = disc(X_fake)\n",
        "    labels_fake = torch.zeros(X_fake.shape[0])\n",
        "    loss_fake = F.bse_loss(out_fake, labels_fake)\n",
        "    loss_fake.backward()\n",
        "    opt_d.step()\n",
        "\n",
        "    total_loss_gen += (loss.item() + loss_fake.item)\n",
        "\n",
        "    # Generator\n",
        "\n",
        "    noise = torch.randn((64, 32), device = device, dtype = torch.float)\n",
        "    X_gfake = gen(noise)\n",
        "    out_gfake = disc(X_gfake)\n",
        "    labels_gfake = torch.ones(X_gfake.shape[0])\n",
        "    loss_fake = F.bse_loss(out_gfake, labels_gfake)\n",
        "\n",
        "    total_loss_gen += (loss.item() + loss_fake.item)\n",
        "\n",
        "  ls_d.append(total_loss_disc)\n",
        "  ls_g.append(total_loss_gen)"
      ],
      "metadata": {
        "id": "uvIndFhVrQNi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}